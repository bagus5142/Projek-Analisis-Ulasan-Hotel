{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad09eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# CELL 1: INSTALASI LIBRARY\n",
    "# Jalankan ini sekali saja di awal.\n",
    "# Tanda seru (!) artinya kita menyuruh terminal komputer melakukan perintah ini.\n",
    "# ========================================================================\n",
    "!pip install pandas torch transformers seaborn matplotlib tqdm openpyxl scikit-learn ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d863f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Konfigurasi selesai. Lanjut ke Cell berikutnya.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: IMPORT & KONFIGURASI\n",
    "# Menyiapkan variabel-variabel utama proyek.\n",
    "# ==============================================================================\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "from tqdm.notebook import tqdm  # Pakai tqdm khusus notebook biar loading bar-nya cantik\n",
    "\n",
    "# --- PENGATURAN TAMPILAN GRAFIK ---\n",
    "sns.set_style(\"whitegrid\") # Biar background grafik ada garis-garis grid (lebih rapi)\n",
    "%matplotlib inline \n",
    "# ^ Perintah \"Magic\" agar grafik muncul langsung di bawah cell ini (bukan pop-up)\n",
    "\n",
    "# --- KONFIGURASI PROYEK ---\n",
    "# Sesuaikan dengan nama folder di GitHub kamu\n",
    "NAMA_FOLDER_DATA = 'DatasetHotel' \n",
    "\n",
    "# Label Kategori (Kamu bisa ubah/tambah list ini sesuai kebutuhan manajemen)\n",
    "# AI akan menggunakan \"Zero-Shot Learning\" untuk mencocokkan review ke kategori ini.\n",
    "CANDIDATE_LABELS = [\n",
    "    \"Kualitas Makanan & Restoran\",      \n",
    "    \"Kebersihan & Kenyamanan Kamar\",    \n",
    "    \"Pelayanan Staf & Keramahan\",       \n",
    "    \"Fasilitas Hotel (Kolam/Gym/Spa)\",  \n",
    "    \"Lokasi & Akses Strategis\",         \n",
    "    \"Infrastruktur (AC/WiFi/Parkir/Air)\", \n",
    "    \"Harga & Value for Money\"           \n",
    "]\n",
    "\n",
    "print(\"‚úÖ Konfigurasi selesai. Lanjut ke Cell berikutnya.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32b098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† MEMUAT KECERDASAN BUATAN (AI MODEL)...\n",
      "‚ö†Ô∏è Menggunakan CPU.\n",
      "‚è≥ Sedang memuat model Multilingual... (Mungkin download lagi sekitar 500MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-xlm-roberta-base-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012CE5AF0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 4521d1ff-ff55-4bf9-b481-b75806fe6089)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Error while downloading from https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012C2C7A0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 405fd16d-9d56-4fd1-a14e-2ad6badfecfb)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012BFB860>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 52444456-d853-4a99-ac90-75568174b9c4)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012BFBF50>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 41c1e1a7-1881-4924-8ab1-f73478a49fb9)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012BFA4E0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: badcbada-c7c9-4408-83c5-363fa9e32c58)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012BF9D30>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 77f92c2d-456f-474a-880e-f8a52ec1f0ec)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012BF9FD0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: c1cb47c3-86a2-4b0c-97a4-fa5150bc394c)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012CE7800>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: a675b4e9-62b6-4aba-ad78-57be33d83523)')' thrown while requesting HEAD https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012CE7E90>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: f3730035-9f13-45d5-a422-4d03307c3519)')' thrown while requesting HEAD https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012CE5B50>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 7f1a608d-2921-485f-9d7d-e90cb62406b2)')' thrown while requesting HEAD https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012C2C7A0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 730a8d51-296d-4912-8290-0a0e238e5e36)')' thrown while requesting HEAD https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012BFAD20>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 162290d9-2c22-4d77-8b44-e8e2f5f9b0c0)')' thrown while requesting HEAD https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin\n",
      "Retrying in 8s [Retry 5/5].\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Falling back to torch.float32 because loading with the original dtype failed on the target device.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: 'NoneType' object has no attribute 'endswith'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012C2DE50>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 9e086cf9-9005-44cd-9957-ff626b892a55)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Error while downloading from https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E013DB9940>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: c7d512ed-5d3f-4fb0-9ef9-3ee45e674df8)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E013D8FBC0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 2c881336-e1f7-4214-b4fc-2a54c1d9f8cc)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E013DD6570>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: fc0354a8-2c83-4bca-a935-ab0d823a7b72)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E012D09490>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 90237044-32b5-45f2-81ed-2101667b417f)')' thrown while requesting GET https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/refs%2Fpr%2F15/model.safetensors\n",
      "Retrying in 8s [Retry 4/5].\n"
     ]
    }
   ],
   "source": [
    "def setup_models():\n",
    "    print(\"üß† MEMUAT KECERDASAN BUATAN (AI MODEL)...\")\n",
    "    \n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    if device == 0:\n",
    "        print(f\"‚úÖ GPU Terdeteksi: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Menggunakan CPU.\")\n",
    "\n",
    "    # --- KITA KEMBALI KE MODEL RINGAN ---\n",
    "    # Model ini lebih kecil (400MB) jadi kemungkinan sukses download lebih besar\n",
    "    model_sentiment = \"w11wo/indonesian-roberta-base-sentiment-classifier\"\n",
    "    model_zeroshot = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    "\n",
    "    try:\n",
    "        print(\"‚è≥ Sedang memuat model... (Harap pastikan internet lancar)\")\n",
    "        clf_sentiment = pipeline(\"sentiment-analysis\", model=model_sentiment, tokenizer=model_sentiment, device=device)\n",
    "        clf_aspect = pipeline(\"zero-shot-classification\", model=model_zeroshot, device=device)\n",
    "        print(\"‚úÖ SUKSES! Model Siap.\")\n",
    "        return clf_sentiment, clf_aspect\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error Internet: {e}\")\n",
    "        return None, None\n",
    "\n",
    "clf_sentiment, clf_aspect = setup_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fa8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 4: FUNGSI PENDUKUNG (DATA LOADING & CLEANING)\n",
    "# ==============================================================================\n",
    "\n",
    "def clean_text_safe(text):\n",
    "    \"\"\"Membersihkan teks tapi JANGAN hapus Emoji/Tanda Baca\"\"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<.*?>', ' ', text)  # Hapus tag HTML\n",
    "    text = re.sub(r'http\\S+', '', text) # Hapus Link/URL\n",
    "    text = \" \".join(text.split())       # Hapus spasi berlebih\n",
    "    return text\n",
    "\n",
    "def load_data(folder_name):\n",
    "    print(f\"üìÇ Mencari data di folder: {folder_name}\")\n",
    "    \n",
    "    # Cek lokasi folder (bisa di folder ini atau folder atasnya)\n",
    "    current_dir = os.getcwd()\n",
    "    target_path = os.path.join(current_dir, folder_name)\n",
    "    \n",
    "    # Jika tidak ketemu, coba cari di folder parent (kalau script ada di dlm folder src)\n",
    "    if not os.path.exists(target_path):\n",
    "        target_path = os.path.join(current_dir, \"..\", folder_name)\n",
    "    \n",
    "    if not os.path.exists(target_path):\n",
    "        print(f\"‚ùå Gagal menemukan folder '{folder_name}'. Cek struktur foldermu.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Cari semua file .csv di dalam sub-folder manapun\n",
    "    files = glob.glob(os.path.join(target_path, \"**\", \"*.csv\"), recursive=True)\n",
    "    all_dfs = []\n",
    "    \n",
    "    print(f\"üîç Ditemukan {len(files)} file CSV. Mulai membaca...\")\n",
    "\n",
    "    for file_path in files:\n",
    "        try:\n",
    "            # --- LOGIKA DETEKSI STRUKTUR FOLDER GITHUB ---\n",
    "            # Path: .../DatasetHotel/BUMN/Bintang3/NamaFile.csv\n",
    "            path_parts = os.path.normpath(file_path).split(os.sep)\n",
    "            \n",
    "            # Ambil nama folder sebagai label\n",
    "            tipe_hotel = path_parts[-3] if len(path_parts) > 3 else \"Unknown\"    # BUMN/KOMPETITOR\n",
    "            kelas_bintang = path_parts[-2] if len(path_parts) > 2 else \"Unknown\" # Bintang3/4/5\n",
    "            nama_hotel = os.path.basename(file_path).replace('.csv', '')\n",
    "\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Normalisasi nama kolom (Cari kolom yang isinya teks review)\n",
    "            col_map = {}\n",
    "            for col in df.columns:\n",
    "                lower_col = col.lower()\n",
    "                if ('review' in lower_col and 'text' in lower_col) or 'content' in lower_col:\n",
    "                    col_map[col] = 'text_review'\n",
    "            \n",
    "            df = df.rename(columns=col_map)\n",
    "            \n",
    "            if 'text_review' in df.columns:\n",
    "                df['Tipe'] = tipe_hotel\n",
    "                df['Kelas'] = kelas_bintang\n",
    "                df['Nama_Hotel'] = nama_hotel\n",
    "                \n",
    "                # Simpan hanya kolom penting\n",
    "                cols = ['text_review', 'Rating', 'Tipe', 'Kelas', 'Nama_Hotel']\n",
    "                valid_cols = [c for c in cols if c in df.columns]\n",
    "                all_dfs.append(df[valid_cols])\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error baca file {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if all_dfs:\n",
    "        final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        # Hapus data kosong & duplikat\n",
    "        final_df = final_df.dropna(subset=['text_review']).drop_duplicates(subset=['text_review'])\n",
    "        print(f\"‚úÖ BERHASIL! Total Data Bersih: {len(final_df)} Review.\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"‚ùå Data Kosong.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"‚úÖ Fungsi siap. Lanjut ke Cell Load Data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 5: LOAD DATA SEKARANG\n",
    "# Mari kita lihat apakah data kamu terbaca dengan benar.\n",
    "# ==============================================================================\n",
    "\n",
    "# Panggil fungsi load\n",
    "df_hotel = load_data(NAMA_FOLDER_DATA)\n",
    "\n",
    "# Tampilkan 5 data teratas sebagai sampel\n",
    "if not df_hotel.empty:\n",
    "    print(\"\\nContoh 5 Data Pertama:\")\n",
    "    display(df_hotel.head()) # 'display' khusus untuk mempercantik tabel di Jupyter\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Tidak ada data untuk ditampilkan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 6: MENJALANKAN ANALISIS AI\n",
    "# Proses ini akan membaca satu per satu review.\n",
    "# ==============================================================================\n",
    "\n",
    "def run_analysis_notebook(df):\n",
    "    if df.empty:\n",
    "        print(\"Data kosong, tidak bisa analisis.\")\n",
    "        return df\n",
    "\n",
    "    print(\"üöÄ Memulai Analisis Sentimen & Topik...\")\n",
    "    \n",
    "    # 1. Bersihkan Teks Dulu\n",
    "    df['clean_text'] = df['text_review'].apply(clean_text_safe)\n",
    "    texts = df['clean_text'].astype(str).tolist()\n",
    "    \n",
    "    results_sentiment = []\n",
    "    results_aspect = []\n",
    "    \n",
    "    # 2. Loop Analisis dengan Progress Bar\n",
    "    for text in tqdm(texts, desc=\"Sedang Menganalisis\"):\n",
    "        # A. Sentimen (IndoBERT)\n",
    "        try:\n",
    "            # Potong teks max 512 karakter (batas kemampuan BERT)\n",
    "            res = clf_sentiment(text[:512], truncation=True, max_length=512)[0]\n",
    "            sentiment_label = res['label']\n",
    "        except:\n",
    "            sentiment_label = \"neutral\"\n",
    "            \n",
    "        # B. Aspek (Zero-Shot)\n",
    "        try:\n",
    "            res = clf_aspect(text[:512], CANDIDATE_LABELS, multi_label=False)\n",
    "            best_aspect = res['labels'][0] # Ambil skor tertinggi\n",
    "        except:\n",
    "            best_aspect = \"Lainnya\"\n",
    "            \n",
    "        results_sentiment.append(sentiment_label)\n",
    "        results_aspect.append(best_aspect)\n",
    "        \n",
    "    # 3. Masukkan Hasil ke Tabel\n",
    "    df['AI_Sentiment'] = results_sentiment\n",
    "    df['AI_Aspek'] = results_aspect\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- JALANKAN ANALISIS ---\n",
    "# Kalau mau tes cepat dulu, hilangkan tanda pagar (#) di baris bawah ini:\n",
    "# df_hotel_sample = df_hotel.head(20) \n",
    "# df_result = run_analysis_notebook(df_hotel_sample)\n",
    "\n",
    "# Kalau mau proses SEMUA data (mungkin lama), pakai baris ini:\n",
    "df_result = run_analysis_notebook(df_hotel)\n",
    "\n",
    "# Simpan ke Excel biar aman\n",
    "df_result.to_excel(\"Hasil_Analisis_Lengkap.xlsx\", index=False)\n",
    "print(\"‚úÖ Analisis Selesai! File Excel 'Hasil_Analisis_Lengkap.xlsx' sudah disimpan.\")\n",
    "\n",
    "# Lihat hasilnya\n",
    "df_result[['text_review', 'AI_Sentiment', 'AI_Aspek']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 7: GRAFIK 1 - PERBANDINGAN TIPE\n",
    "# ==============================================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Membuat Bar Chart\n",
    "sns.countplot(data=df_result, x='Tipe', hue='AI_Sentiment', palette='viridis')\n",
    "\n",
    "plt.title('Head-to-Head: Sentimen BUMN vs KOMPETITOR', fontsize=14)\n",
    "plt.xlabel('Tipe Hotel')\n",
    "plt.ylabel('Jumlah Review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 8: GRAFIK 2 - PERBANDINGAN KELAS BINTANG\n",
    "# ==============================================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "try:\n",
    "    # Urutkan agar grafik rapi (Bintang3 -> Bintang4 -> Bintang5)\n",
    "    order_bintang = sorted(df_result['Kelas'].unique())\n",
    "    \n",
    "    sns.countplot(data=df_result, x='Kelas', hue='AI_Sentiment', order=order_bintang, palette='rocket')\n",
    "    \n",
    "    plt.title('Distribusi Sentimen Berdasarkan Kelas Bintang', fontsize=14)\n",
    "    plt.xlabel('Kelas Hotel')\n",
    "    plt.ylabel('Jumlah Review')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Gagal membuat grafik bintang: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 9: GRAFIK 3 - PETA MASALAH (Review Negatif Saja)\n",
    "# ==============================================================================\n",
    "\n",
    "# Filter: Ambil hanya yang sentimennya NEGATIVE\n",
    "df_neg = df_result[df_result['AI_Sentiment'] == 'negative']\n",
    "\n",
    "if not df_neg.empty:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Hitung aspek mana yang paling banyak dikeluhkan\n",
    "    order_aspek = df_neg['AI_Aspek'].value_counts().index\n",
    "    \n",
    "    # Buat grafik horizontal\n",
    "    sns.countplot(data=df_neg, y='AI_Aspek', hue='Tipe', order=order_aspek, palette='magma')\n",
    "    \n",
    "    plt.title('TOP KELUHAN UTAMA (Berdasarkan Review Negatif)', fontsize=14)\n",
    "    plt.xlabel('Jumlah Komplain')\n",
    "    plt.ylabel('Kategori Masalah')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"üéâ Wow! Tidak ada review negatif sama sekali.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
