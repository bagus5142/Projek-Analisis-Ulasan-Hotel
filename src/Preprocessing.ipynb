{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f21016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501947b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menyiapkan Engine di: CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000002ABA0711A80>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Siap!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. SETUP MODEL\n",
    "# ==========================================\n",
    "# Menggunakan Float16 agar 2x lebih cepat dan hemat memori\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Menyiapkan Engine di: {device.upper()}\")\n",
    "\n",
    "MODEL_NAME = \"facebook/nllb-200-distilled-600M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load model dengan presisi rendah (FP16) untuk kecepatan maksimal\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "\n",
    "print(\"Model Siap!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7184c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. KONFIGURASI PATH\n",
    "# ==========================================\n",
    "RAW_PATH = \"../DatasetHotel/KOMPETITORB5\"\n",
    "CLEAN_PATH = \"../DatasetHotelCLEAN/KOMPETITORB5\"\n",
    "os.makedirs(CLEAN_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2388332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kamus Slang (Tetap sama)\n",
    "slang_dict = {\n",
    "    'yg': 'yang', 'ga': 'tidak', 'gak': 'tidak', 'nggak': 'tidak',\n",
    "    'tp': 'tapi', 'krn': 'karena', 'utk': 'untuk', 'sdh': 'sudah',\n",
    "    'udh': 'sudah', 'blm': 'belum', 'dgn': 'dengan', 'dlm': 'dalam',\n",
    "    'bgt': 'banget', 'tdk': 'tidak', 'jgn': 'jangan', 'krg': 'kurang',\n",
    "    'sy': 'saya', 'ak': 'aku', 'kalo': 'kalau', 'kl': 'kalau',\n",
    "    'dr': 'dari', 'bs': 'bisa', 'kmn': 'kemana', 'tmn': 'teman',\n",
    "    'bgs': 'bagus', 'dtg': 'datang', 'br': 'baru', 'ok': 'oke',\n",
    "    'thx': 'terima kasih', 'makasih': 'terima kasih', 'tks': 'terima kasih',\n",
    "    'min': 'minus', 'plus': 'tambah', 'chek': 'check', 'chekout': 'check out',\n",
    "    'chekin': 'check in', 'in': 'masuk', 'out': 'keluar', 'pas': 'saat',\n",
    "    'pd': 'pada', 'pake': 'pakai', 'sm': 'sama', 'lbh': 'lebih',\n",
    "    'bkn': 'bukan', 'spt': 'seperti', 'jd': 'jadi', 'aja': 'saja',\n",
    "    'aj': 'saja', 'kmr': 'kamar', 'kmar': 'kamar', 'mnt': 'minta',\n",
    "    'dl': 'dulu', 'skrg': 'sekarang', 'dg': 'dengan', 'yk': 'yogyakarta'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0dd69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_advanced(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    words = text.split()\n",
    "    normalized_words = [slang_dict.get(word, word) for word in words]\n",
    "    text = ' '.join(normalized_words)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aea1330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Translate \n",
    "def translate_fast(text_list, batch_size=64):\n",
    "    results = []\n",
    "    tokenizer.src_lang = \"eng_Latn\"\n",
    "    forced_bos_token_id = tokenizer.convert_tokens_to_ids(\"ind_Latn\")\n",
    "    \n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i+batch_size]\n",
    "        \n",
    "        # Max length 128 cukup untuk ulasan hotel, 256 bikin lambat\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            translated_tokens = model.generate(\n",
    "                **inputs, \n",
    "                forced_bos_token_id=forced_bos_token_id, \n",
    "                max_new_tokens=128,\n",
    "                num_beams=1,        # Greedy Search (Kunci Kecepatan!)\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        decoded = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "        results.extend(decoded)\n",
    "        \n",
    "        # Hapus sisa batch segera\n",
    "        del inputs, translated_tokens\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f677cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mulai Memproses 26 File...\n",
      "\n",
      "[1/26] BatamMarriotHotelHabourBay.csv... Selesai (428 data).\n",
      "[2/26] BestWesternPremierPanbil-Batam.csv... Selesai (592 data).\n",
      "[3/26] GrandAstonCityHall-Medan.csv... Selesai (704 data).\n",
      "[4/26] InterContinentalBaliResort-Bali.csv... Selesai (227 data).\n",
      "[5/26] InterContinentalBaliSanurResort-Bali (1).csv... Selesai (288 data).\n",
      "[6/26] InterContinentalDagoPakar-Bandung.csv... Selesai (608 data).\n",
      "[7/26] InterContinentalJakartaPondokIndah-Jakarta.csv... Selesai (667 data).\n",
      "[8/26] InterContinentalResidenceJakartaPondokIndah-Jakarta.csv... Selesai (685 data).\n",
      "[9/26] JWMarriotHotelJakarta.csv... Selesai (683 data).\n",
      "[10/26] JWMarriotHotelSurabaya.csv... Selesai (609 data).\n",
      "[11/26] JWMarriotMedan.csv... Selesai (704 data).\n",
      "[12/26] MovenpickHoteljakartaCityCentre.csv... Selesai (495 data).\n",
      "[13/26] PullmanBaliLegianBeach (1).csv... Selesai (714 data).\n",
      "[14/26] PullmanBandungGrandCentral.csv... Selesai (723 data).\n",
      "[15/26] PullmanJakartaCentralPark.csv... Selesai (394 data).\n",
      "[16/26] PullmanJakartaIndonesiaThamrinCBD.csv... Selesai (577 data).\n",
      "[17/26] PullmanLombokMerujaniMandalikaBeachResort.csv... Selesai (486 data).\n",
      "[18/26] RafflesJakarta.csv... Selesai (609 data).\n",
      "[19/26] Rafflessbali (1).csv... Selesai (388 data).\n",
      "[20/26] SheratonGrandJakartaGandariaCityHotel.csv... Selesai (644 data).\n",
      "[21/26] SofitelBaliNusaDuaBeachResort.csv... Selesai (743 data).\n",
      "[22/26] SwissotelJakartaPIKAvenue.csv... Selesai (643 data).\n",
      "[23/26] TheHermitageATributePortfolioHotel,Jakarta.csv... Selesai (564 data).\n",
      "[24/26] TheSt.RegisJakarta.csv... Selesai (555 data).\n",
      "[25/26] TheWestinJakarta.csv... Selesai (479 data).\n",
      "[26/26] WestinBatam.csv... Selesai (61 data).\n",
      "\n",
      "SEMUA SELESAI!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. EKSEKUSI\n",
    "# ==========================================\n",
    "BATCH_SIZE = 64 # Bisa 64 karena pakai FP16 (lebih ringan)\n",
    "\n",
    "files = [f for f in os.listdir(RAW_PATH) if f.endswith(\".csv\")]\n",
    "print(f\"\\nMulai Memproses {len(files)} File...\\n\")\n",
    "\n",
    "for idx, filename in enumerate(files):\n",
    "    print(f\"[{idx+1}/{len(files)}] {filename}...\", end=\" \")\n",
    "    \n",
    "    try:\n",
    "        input_path = os.path.join(RAW_PATH, filename)\n",
    "        df = pd.read_csv(input_path)\n",
    "\n",
    "        # Cleaning\n",
    "        df = df.dropna(subset=['Review Text'])\n",
    "        blacklist = ['N/A','n/a', 'na', 'nan', '-', '', ' ', 'null']\n",
    "        df = df[~df['Review Text'].astype(str).str.lower().str.strip().isin(blacklist)]\n",
    "        df = df.drop(columns=[c for c in ['No', 'Review Count'] if c in df.columns], errors='ignore')\n",
    "        \n",
    "        df['Review Text Cleaned'] = df['Review Text'].apply(clean_text_advanced)\n",
    "        df = df[df['Review Text Cleaned'].str.len() > 2]\n",
    "\n",
    "        # Translate\n",
    "        texts = df['Review Text Cleaned'].tolist()\n",
    "        if len(texts) > 0:\n",
    "            # Tidak pakai tqdm di dalam sini biar log bersih dan cepat\n",
    "            translated_results = []\n",
    "            for i in range(0, len(texts), BATCH_SIZE):\n",
    "                batch = texts[i:i+BATCH_SIZE]\n",
    "                translated_results.extend(translate_fast(batch, BATCH_SIZE))\n",
    "            \n",
    "            df['Review Text Cleaned'] = translated_results\n",
    "            \n",
    "            # Save\n",
    "            clean_filename = filename.replace(\".csv\", \"_Clean.csv\")\n",
    "            output_path = os.path.join(CLEAN_PATH, clean_filename)\n",
    "            \n",
    "            df = df.drop(columns=['Review Text'], errors='ignore')\n",
    "            df = df.rename(columns={'Review Text Cleaned': 'Review Text'})\n",
    "            df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"Selesai ({len(texts)} data).\")\n",
    "        else:\n",
    "            print(\"Kosong.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    # CLEANUP (Hanya butuh 0.5 detik tapi menyelamatkan Anda dari macet)\n",
    "    try:\n",
    "        del df, texts\n",
    "        if 'translated_results' in locals(): del translated_results\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    except: pass\n",
    "\n",
    "print(\"\\nSEMUA SELESAI!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
